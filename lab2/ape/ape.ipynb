{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765d87a4-ab97-452e-8c8c-b50bd2c7399f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirement.txt\n",
    "\n",
    "# !pip install sentence_transformers\n",
    "\n",
    "# !pip install sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a98a21-4eb3-4c8d-9204-50435ac3d79d",
   "metadata": {},
   "source": [
    "# Automatic Prompt Engineering (APE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4693f9f-d8aa-4057-9c4b-a4e0c4958921",
   "metadata": {},
   "source": [
    "## copy of kendra_chat_llm.py code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1e1b3017-af95-48db-b715-1ba03eba74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------------------##\n",
    "## modified from ../kendra_chat_llm.py\n",
    "##-------------------------------------##\n",
    "\n",
    "from langchain.retrievers import AmazonKendraRetriever\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "\n",
    "MAX_HISTORY_LENGTH = 5\n",
    "\n",
    "model_parameters = {           \n",
    "    \"max_new_tokens\": 200, \n",
    "    \"temperature\":0.1, \n",
    "    \"seed\":0, \n",
    "    \"stop\": [\"Human:\"], \n",
    "    \"num_beams\":1, \n",
    "    \"return_full_text\": False\n",
    "    }\n",
    "\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": {**model_kwargs}})\n",
    "        return input_str.encode('utf-8')\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generated_text\"]\n",
    "\n",
    "    \n",
    "def build_chain(prompt_template=None):\n",
    "    region = os.environ[\"AWS_REGION\"]\n",
    "    kendra_index_id = os.environ[\"KENDRA_INDEX_ID\"]\n",
    "    endpoint_name = os.environ[\"SAGEMAKER_LLM_ENDPOINT\"]\n",
    "\n",
    "\n",
    "    content_handler = ContentHandler()\n",
    "\n",
    "    llm = SagemakerEndpoint(\n",
    "        endpoint_name=endpoint_name,\n",
    "        region_name=region,\n",
    "        model_kwargs=model_parameters,\n",
    "        content_handler=content_handler\n",
    "    )\n",
    "\n",
    "    retriever = AmazonKendraRetriever(index_id=kendra_index_id)\n",
    "\n",
    "\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "    condense_qa_template = \"\"\"\n",
    "        Given the following conversation and a follow up question, rephrase the follow up question \n",
    "        to be a standalone question.\n",
    "\n",
    "        Chat History:\n",
    "        {chat_history}\n",
    "        Follow Up Input: {question}\n",
    "        Standalone question:\"\"\"\n",
    "    \n",
    "    standalone_question_prompt = PromptTemplate.from_template(\n",
    "        condense_qa_template)\n",
    "\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        condense_question_prompt=standalone_question_prompt,\n",
    "        return_source_documents=False,\n",
    "        combine_docs_chain_kwargs={\"prompt\": PROMPT})\n",
    "    return qa\n",
    "\n",
    "\n",
    "def run_chain(chain, prompt: str, history=[]):\n",
    "    result = chain({\"question\": prompt, \"chat_history\": history})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7048e4b-5769-4264-8700-d5a0dc01a9ef",
   "metadata": {},
   "source": [
    "### configure AWS_REGION, KENDRA_INDEX_ID, SAGEMAKE_LLM_ENDPOINT variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8a530842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['AWS_REGION'] = 'us-east-1'\n",
    "os.environ[\"KENDRA_INDEX_ID\"] = '6bf94090-16d3-4c34-b541-2eaadb4fe5f1'\n",
    "os.environ[\"SAGEMAKER_LLM_ENDPOINT\"] = \"huggingface-pytorch-tgi-inference-2023-07-18-11-41-50-057\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48216206-62a5-4d00-aec0-adbca5d66872",
   "metadata": {},
   "source": [
    "### sample of Q & A test bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "61cb8fe4-de66-4408-ab57-94ab79443fd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_bank():\n",
    "    test_bank = \"\"\"Question: What is AWS Kendra?\n",
    "    Answer: AWS Kendra is an intelligent search service powered by machine learning that provides natural language search capabilities for various data sources and content.\n",
    "\n",
    "    Question: What types of data sources does AWS Kendra support for indexing?\n",
    "    Answer: AWS Kendra supports various data sources, including Amazon S3, SharePoint Online, Salesforce, ServiceNow, Relational Databases, and more.\n",
    "\n",
    "    Question: How does AWS Kendra handle natural language queries?\n",
    "    Answer: AWS Kendra uses machine learning models to understand natural language queries and provide relevant results using contextual understanding and ranking.\n",
    "\n",
    "    Question: What are the benefits of using AWS Kendra for enterprise search?\n",
    "    Answer: Some benefits of AWS Kendra include improved search accuracy, reduced time to find relevant information, and support for multiple data sources.\n",
    "\n",
    "    Question: How does AWS Kendra ensure security and compliance?\n",
    "    Answer: AWS Kendra encrypts data at rest and in transit, provides access control via AWS Identity and Access Management (IAM), and is compliant with various security standards.\n",
    "\n",
    "    Question: Can AWS Kendra be used for both internal and external search scenarios?\n",
    "    Answer: Yes, AWS Kendra can be used for both internal enterprise search (intranet) and external customer-facing search (internet) scenarios.\n",
    "\n",
    "    Question: What are custom data sources in AWS Kendra?\n",
    "    Answer: Custom data sources in AWS Kendra allow you to integrate your own data repositories or applications into the search index.\n",
    "\n",
    "    Question: Can AWS Kendra search across multiple languages?\n",
    "    Answer: Yes, AWS Kendra supports multiple languages and can perform multilingual search queries.\n",
    "\n",
    "    Question: How does AWS Kendra handle synonyms and acronyms?\n",
    "    Answer: AWS Kendra automatically recognizes synonyms and acronyms, improving search accuracy and understanding user queries.\n",
    "\n",
    "    Question: Does AWS Kendra support natural language processing (NLP)?\n",
    "    Answer: Yes, AWS Kendra uses natural language processing to understand complex user queries and return relevant search results.\"\"\"\n",
    "\n",
    "    tmp = [i for i in test_bank.split(\"\\n\") if i != '']\n",
    "    qa_dict = {}\n",
    "\n",
    "    for qq, aa in [tmp[i: i + 2] for i in range(0, len(tmp), 2)]:\n",
    "        qa_dict[qq.split('Question: ')[-1]] = aa.split('Answer: ')[-1]\n",
    "    return qa_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f8949-1417-4b03-adeb-9cfc5282c277",
   "metadata": {},
   "source": [
    "### define evaluation criteria, cosine similarity between the ground truth and the generated answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5ac60929-d921-461f-bfce-2b5b0a2ced91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load a pre-trained SentenceTransformer model\n",
    "model_name = \"paraphrase-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# evaluation score\n",
    "def get_ans_score(ground_truth, generated_answer, model):\n",
    "    generated_answer_embedding = model.encode(generated_answer, convert_to_tensor=True)\n",
    "    ground_truth_embedding = model.encode(ground_truth, convert_to_tensor=True)\n",
    "    return util.pytorch_cos_sim(generated_answer_embedding, ground_truth_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd2e852-dec6-45cb-b6c0-fcb268f7a991",
   "metadata": {},
   "source": [
    "### define prompt template used in RAG + Kendra, and set up the Q & A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "ae479c66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    The following is a friendly conversation between a human and an AI. \n",
    "    The AI is talkative and provides lots of specific details from its context.\n",
    "    If the AI does not know the answer to a question, it truthfully says it \n",
    "    does not know.\n",
    "    {context}\n",
    "    Instruction: Based on the above documents, provide a detailed answer for, {question} Answer \"don't know\" \n",
    "    if not present in the document. \n",
    "    Solution:\"\"\"\n",
    "\n",
    "qa_bank = get_test_bank()\n",
    "chain = build_chain(prompt_template=prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873e08d1-f1ea-4ad2-b1d7-443782892001",
   "metadata": {},
   "source": [
    "### get initial score with j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d032fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_dict = {}\n",
    "for qq, aa in tqdm(qa_bank.items()):\n",
    "    ans = run_chain(chain, prompt = qq)\n",
    "    score = get_ans_score(aa, ans['answer'].strip(), model=model)\n",
    "    score_dict[qq] = {'generated_answer': ans['answer'].strip(), 'correct_answer': aa, 'score': score.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c45e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(score_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d3bd9-4563-4452-9176-f1ce3d1601be",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "74afff00-c209-402f-ae1c-bef483666fcf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region = os.environ[\"AWS_REGION\"]\n",
    "kendra_index_id = os.environ[\"KENDRA_INDEX_ID\"]\n",
    "endpoint_name = os.environ[\"SAGEMAKER_LLM_ENDPOINT\"]\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name=endpoint_name,\n",
    "    region_name=region,\n",
    "    model_kwargs=model_parameters,\n",
    "    content_handler=content_handler\n",
    ")\n",
    "\n",
    "prompt_template_improve = \"\"\"Suggest a more detailed prompt for the following enclosed in three single quotes. \n",
    "                            The prompt should still be an question. The prompt should be different with the original. \n",
    "                            '''{input_text}''' \"\"\"\n",
    "prompt_improve = PromptTemplate.from_template(prompt_template_improve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "4c933252",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is AWS Kendra? What is AWS Kendra?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:07<01:07,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What types of data sources does AWS Kendra support for indexing? What types of data sources does AWS Kendra support for indexing?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:15<01:02,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does AWS Kendra handle natural language queries? What are some of the challenges that AWS Kendra might face when handling natural language queries?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:23<00:55,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are the benefits of using AWS Kendra for enterprise search? What are the advantages of using AWS Kendra for enterprise search?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:31<00:47,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does AWS Kendra ensure security and compliance? What measures does AWS Kendra take to ensure security and compliance?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:39<00:39,  7.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can AWS Kendra be used for both internal and external search scenarios? What are the advantages and disadvantages of using AWS Kendra for internal and external search scenarios?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:47<00:32,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are custom data sources in AWS Kendra? What are custom data sources in AWS Kendra?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:55<00:24,  8.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can AWS Kendra search across multiple languages? What other languages can AWS Kendra search across?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [01:03<00:16,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How does AWS Kendra handle synonyms and acronyms? What are some common synonyms and acronyms used in AWS Kendra and how does the platform handle them?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [01:11<00:08,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does AWS Kendra support natural language processing (NLP)? What specific natural language processing (NLP) capabilities does AWS Kendra offer?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:20<00:00,  8.02s/it]\n"
     ]
    }
   ],
   "source": [
    "score_dict_updated = {}\n",
    "for qq, aa in tqdm(qa_bank.items()):\n",
    "    qq_refined = llm(prompt_improve.format(input_text=qq)).strip()\n",
    "    print(qq, qq_refined)\n",
    "    ans = run_chain(chain, prompt = qq_refined)\n",
    "    score = get_ans_score(aa, ans['answer'].strip(), model=model)\n",
    "    score_dict_updated[qq] = {'generated_answer': ans['answer'].strip(), 'correct_answer': aa, 'score': score.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "b2faf303",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>What is AWS Kendra?</th>\n",
       "      <th>What types of data sources does AWS Kendra support for indexing?</th>\n",
       "      <th>How does AWS Kendra handle natural language queries?</th>\n",
       "      <th>What are the benefits of using AWS Kendra for enterprise search?</th>\n",
       "      <th>How does AWS Kendra ensure security and compliance?</th>\n",
       "      <th>Can AWS Kendra be used for both internal and external search scenarios?</th>\n",
       "      <th>What are custom data sources in AWS Kendra?</th>\n",
       "      <th>Can AWS Kendra search across multiple languages?</th>\n",
       "      <th>How does AWS Kendra handle synonyms and acronyms?</th>\n",
       "      <th>Does AWS Kendra support natural language processing (NLP)?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>generated_answer</th>\n",
       "      <td>AWS Kendra is a cloud-based service that provi...</td>\n",
       "      <td>AWS Kendra supports indexing documents in a va...</td>\n",
       "      <td>AWS Kendra is a natural language processing (N...</td>\n",
       "      <td>The main advantages of using AWS Kendra for en...</td>\n",
       "      <td>AWS Kendra takes several measures to ensure se...</td>\n",
       "      <td>AWS Kendra can be used to improve search resul...</td>\n",
       "      <td>A custom data source is a data source that is ...</td>\n",
       "      <td>AWS Kendra can search across multiple language...</td>\n",
       "      <td>AWS Kendra handles synonyms and acronyms by us...</td>\n",
       "      <td>1. Understand the structure of the natural lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct_answer</th>\n",
       "      <td>AWS Kendra is an intelligent search service po...</td>\n",
       "      <td>AWS Kendra supports various data sources, incl...</td>\n",
       "      <td>AWS Kendra uses machine learning models to und...</td>\n",
       "      <td>Some benefits of AWS Kendra include improved s...</td>\n",
       "      <td>AWS Kendra encrypts data at rest and in transi...</td>\n",
       "      <td>Yes, AWS Kendra can be used for both internal ...</td>\n",
       "      <td>Custom data sources in AWS Kendra allow you to...</td>\n",
       "      <td>Yes, AWS Kendra supports multiple languages an...</td>\n",
       "      <td>AWS Kendra automatically recognizes synonyms a...</td>\n",
       "      <td>Yes, AWS Kendra uses natural language processi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.767183</td>\n",
       "      <td>0.741995</td>\n",
       "      <td>0.670145</td>\n",
       "      <td>0.738057</td>\n",
       "      <td>0.746491</td>\n",
       "      <td>0.782671</td>\n",
       "      <td>0.627521</td>\n",
       "      <td>0.754128</td>\n",
       "      <td>0.596884</td>\n",
       "      <td>0.273528</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                What is AWS Kendra?  \\\n",
       "generated_answer  AWS Kendra is a cloud-based service that provi...   \n",
       "correct_answer    AWS Kendra is an intelligent search service po...   \n",
       "score                                                      0.767183   \n",
       "\n",
       "                 What types of data sources does AWS Kendra support for indexing?  \\\n",
       "generated_answer  AWS Kendra supports indexing documents in a va...                 \n",
       "correct_answer    AWS Kendra supports various data sources, incl...                 \n",
       "score                                                      0.741995                 \n",
       "\n",
       "                 How does AWS Kendra handle natural language queries?  \\\n",
       "generated_answer  AWS Kendra is a natural language processing (N...     \n",
       "correct_answer    AWS Kendra uses machine learning models to und...     \n",
       "score                                                      0.670145     \n",
       "\n",
       "                 What are the benefits of using AWS Kendra for enterprise search?  \\\n",
       "generated_answer  The main advantages of using AWS Kendra for en...                 \n",
       "correct_answer    Some benefits of AWS Kendra include improved s...                 \n",
       "score                                                      0.738057                 \n",
       "\n",
       "                 How does AWS Kendra ensure security and compliance?  \\\n",
       "generated_answer  AWS Kendra takes several measures to ensure se...    \n",
       "correct_answer    AWS Kendra encrypts data at rest and in transi...    \n",
       "score                                                      0.746491    \n",
       "\n",
       "                 Can AWS Kendra be used for both internal and external search scenarios?  \\\n",
       "generated_answer  AWS Kendra can be used to improve search resul...                        \n",
       "correct_answer    Yes, AWS Kendra can be used for both internal ...                        \n",
       "score                                                      0.782671                        \n",
       "\n",
       "                        What are custom data sources in AWS Kendra?  \\\n",
       "generated_answer  A custom data source is a data source that is ...   \n",
       "correct_answer    Custom data sources in AWS Kendra allow you to...   \n",
       "score                                                      0.627521   \n",
       "\n",
       "                   Can AWS Kendra search across multiple languages?  \\\n",
       "generated_answer  AWS Kendra can search across multiple language...   \n",
       "correct_answer    Yes, AWS Kendra supports multiple languages an...   \n",
       "score                                                      0.754128   \n",
       "\n",
       "                  How does AWS Kendra handle synonyms and acronyms?  \\\n",
       "generated_answer  AWS Kendra handles synonyms and acronyms by us...   \n",
       "correct_answer    AWS Kendra automatically recognizes synonyms a...   \n",
       "score                                                      0.596884   \n",
       "\n",
       "                 Does AWS Kendra support natural language processing (NLP)?  \n",
       "generated_answer  1. Understand the structure of the natural lan...          \n",
       "correct_answer    Yes, AWS Kendra uses natural language processi...          \n",
       "score                                                      0.273528          "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(score_dict_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73bc763-07fd-4abd-876d-483bba8b40da",
   "metadata": {
    "tags": []
   },
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Base Python 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-base-python-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
