{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765d87a4-ab97-452e-8c8c-b50bd2c7399f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install -r requirement.txt\n",
    "\n",
    "# !pip install sentence_transformers\n",
    "\n",
    "# !pip install sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a98a21-4eb3-4c8d-9204-50435ac3d79d",
   "metadata": {},
   "source": [
    "# Automatic Prompt Engineering (APE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4693f9f-d8aa-4057-9c4b-a4e0c4958921",
   "metadata": {},
   "source": [
    "## copy of kendra_chat_llm.py code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1e1b3017-af95-48db-b715-1ba03eba74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "##-------------------------------------##\n",
    "## modified from ../kendra_chat_llm.py\n",
    "##-------------------------------------##\n",
    "\n",
    "from langchain.retrievers import AmazonKendraRetriever\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "class bcolors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'\n",
    "\n",
    "\n",
    "MAX_HISTORY_LENGTH = 5\n",
    "\n",
    "model_parameters = {           \n",
    "    \"max_new_tokens\": 200, \n",
    "    \"temperature\":0.1, \n",
    "    \"seed\":0, \n",
    "    \"stop\": [\"Human:\"], \n",
    "    \"num_beams\":1, \n",
    "    \"return_full_text\": False\n",
    "    }\n",
    "\n",
    "\n",
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: dict) -> bytes:\n",
    "        input_str = json.dumps({\"inputs\": prompt, \"parameters\": {**model_kwargs}})\n",
    "        return input_str.encode('utf-8')\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        return response_json[0][\"generated_text\"]\n",
    "\n",
    "    \n",
    "def build_chain(prompt_template=None):\n",
    "    region = os.environ[\"AWS_REGION\"]\n",
    "    kendra_index_id = os.environ[\"KENDRA_INDEX_ID\"]\n",
    "    endpoint_name = os.environ[\"SAGEMAKER_LLM_ENDPOINT\"]\n",
    "\n",
    "\n",
    "    content_handler = ContentHandler()\n",
    "\n",
    "    llm = SagemakerEndpoint(\n",
    "        endpoint_name=endpoint_name,\n",
    "        region_name=region,\n",
    "        model_kwargs=model_parameters,\n",
    "        content_handler=content_handler\n",
    "    )\n",
    "\n",
    "    retriever = AmazonKendraRetriever(index_id=kendra_index_id)\n",
    "\n",
    "\n",
    "    PROMPT = PromptTemplate(\n",
    "        template=prompt_template, input_variables=[\"context\", \"question\"]\n",
    "    )\n",
    "\n",
    "    condense_qa_template = \"\"\"\n",
    "        Given the following conversation and a follow up question, rephrase the follow up question \n",
    "        to be a standalone question.\n",
    "\n",
    "        Chat History:\n",
    "        {chat_history}\n",
    "        Follow Up Input: {question}\n",
    "        Standalone question:\"\"\"\n",
    "    \n",
    "    standalone_question_prompt = PromptTemplate.from_template(\n",
    "        condense_qa_template)\n",
    "\n",
    "    qa = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        condense_question_prompt=standalone_question_prompt,\n",
    "        return_source_documents=False,\n",
    "        combine_docs_chain_kwargs={\"prompt\": PROMPT})\n",
    "    return qa\n",
    "\n",
    "\n",
    "def run_chain(chain, prompt: str, history=[]):\n",
    "    result = chain({\"question\": prompt, \"chat_history\": history})\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7048e4b-5769-4264-8700-d5a0dc01a9ef",
   "metadata": {},
   "source": [
    "### configure AWS_REGION, KENDRA_INDEX_ID, SAGEMAKE_LLM_ENDPOINT variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8a530842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['AWS_REGION'] = 'us-east-1'\n",
    "os.environ[\"KENDRA_INDEX_ID\"] = '6bf94090-16d3-4c34-b541-2eaadb4fe5f1'\n",
    "os.environ[\"SAGEMAKER_LLM_ENDPOINT\"] = \"huggingface-pytorch-tgi-inference-2023-07-18-11-41-50-057\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48216206-62a5-4d00-aec0-adbca5d66872",
   "metadata": {},
   "source": [
    "### sample of Q & A test bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "61cb8fe4-de66-4408-ab57-94ab79443fd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_bank():\n",
    "    test_bank = \"\"\"Question: What is AWS Kendra?\n",
    "    Answer: AWS Kendra is an intelligent search service powered by machine learning that provides natural language search capabilities for various data sources and content.\n",
    "\n",
    "    Question: What types of data sources does AWS Kendra support for indexing?\n",
    "    Answer: AWS Kendra supports various data sources, including Amazon S3, SharePoint Online, Salesforce, ServiceNow, Relational Databases, and more.\n",
    "\n",
    "    Question: How does AWS Kendra handle natural language queries?\n",
    "    Answer: AWS Kendra uses machine learning models to understand natural language queries and provide relevant results using contextual understanding and ranking.\n",
    "\n",
    "    Question: What are the benefits of using AWS Kendra for enterprise search?\n",
    "    Answer: Some benefits of AWS Kendra include improved search accuracy, reduced time to find relevant information, and support for multiple data sources.\n",
    "\n",
    "    Question: How does AWS Kendra ensure security and compliance?\n",
    "    Answer: AWS Kendra encrypts data at rest and in transit, provides access control via AWS Identity and Access Management (IAM), and is compliant with various security standards.\n",
    "\n",
    "    Question: Can AWS Kendra be used for both internal and external search scenarios?\n",
    "    Answer: Yes, AWS Kendra can be used for both internal enterprise search (intranet) and external customer-facing search (internet) scenarios.\n",
    "\n",
    "    Question: What are custom data sources in AWS Kendra?\n",
    "    Answer: Custom data sources in AWS Kendra allow you to integrate your own data repositories or applications into the search index.\n",
    "\n",
    "    Question: Can AWS Kendra search across multiple languages?\n",
    "    Answer: Yes, AWS Kendra supports multiple languages and can perform multilingual search queries.\n",
    "\n",
    "    Question: How does AWS Kendra handle synonyms and acronyms?\n",
    "    Answer: AWS Kendra automatically recognizes synonyms and acronyms, improving search accuracy and understanding user queries.\n",
    "\n",
    "    Question: Does AWS Kendra support natural language processing (NLP)?\n",
    "    Answer: Yes, AWS Kendra uses natural language processing to understand complex user queries and return relevant search results.\"\"\"\n",
    "\n",
    "    tmp = [i for i in test_bank.split(\"\\n\") if i != '']\n",
    "    qa_dict = {}\n",
    "\n",
    "    for qq, aa in [tmp[i: i + 2] for i in range(0, len(tmp), 2)]:\n",
    "        qa_dict[qq.split('Question: ')[-1]] = aa.split('Answer: ')[-1]\n",
    "    return qa_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2f8949-1417-4b03-adeb-9cfc5282c277",
   "metadata": {},
   "source": [
    "### define evaluation criteria, cosine similarity between the ground truth and the generated answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5ac60929-d921-461f-bfce-2b5b0a2ced91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load a pre-trained SentenceTransformer model\n",
    "model_name = \"paraphrase-mpnet-base-v2\"\n",
    "model = SentenceTransformer(model_name)\n",
    "\n",
    "# evaluation score\n",
    "def get_ans_score(ground_truth, generated_answer, model):\n",
    "    generated_answer_embedding = model.encode(generated_answer, convert_to_tensor=True)\n",
    "    ground_truth_embedding = model.encode(ground_truth, convert_to_tensor=True)\n",
    "    return util.pytorch_cos_sim(generated_answer_embedding, ground_truth_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd2e852-dec6-45cb-b6c0-fcb268f7a991",
   "metadata": {},
   "source": [
    "### define prompt template used in RAG + Kendra, and set up the Q & A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "ae479c66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    The following is a friendly conversation between a human and an AI. \n",
    "    The AI is talkative and provides lots of specific details from its context.\n",
    "    If the AI does not know the answer to a question, it truthfully says it \n",
    "    does not know.\n",
    "    {context}\n",
    "    Instruction: Based on the above documents, provide a detailed answer for, {question} Answer \"don't know\" \n",
    "    if not present in the document. \n",
    "    Solution:\"\"\"\n",
    "\n",
    "qa_bank = get_test_bank()\n",
    "chain = build_chain(prompt_template=prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873e08d1-f1ea-4ad2-b1d7-443782892001",
   "metadata": {},
   "source": [
    "### get initial score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "70d032fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:09<00:00,  6.99s/it]\n"
     ]
    }
   ],
   "source": [
    "score_dict = {}\n",
    "for qq, aa in tqdm(qa_bank.items()):\n",
    "    ans = run_chain(chain, prompt = qq)\n",
    "    score = get_ans_score(aa, ans['answer'].strip(), model=model)\n",
    "    score_dict[qq] = {'generated_answer': ans['answer'].strip(), 'correct_answer': aa, 'score': score.item()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "37c45e95",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>What is AWS Kendra?</th>\n",
       "      <th>What types of data sources does AWS Kendra support for indexing?</th>\n",
       "      <th>How does AWS Kendra handle natural language queries?</th>\n",
       "      <th>What are the benefits of using AWS Kendra for enterprise search?</th>\n",
       "      <th>How does AWS Kendra ensure security and compliance?</th>\n",
       "      <th>Can AWS Kendra be used for both internal and external search scenarios?</th>\n",
       "      <th>What are custom data sources in AWS Kendra?</th>\n",
       "      <th>Can AWS Kendra search across multiple languages?</th>\n",
       "      <th>How does AWS Kendra handle synonyms and acronyms?</th>\n",
       "      <th>Does AWS Kendra support natural language processing (NLP)?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>generated_answer</th>\n",
       "      <td>AWS Kendra is a cloud-based service that provi...</td>\n",
       "      <td>AWS Kendra supports indexing documents in a va...</td>\n",
       "      <td>AWS Kendra uses natural language processing an...</td>\n",
       "      <td>The benefits of using AWS Kendra for enterpris...</td>\n",
       "      <td>AWS Kendra provides a number of security and c...</td>\n",
       "      <td>Yes, AWS Kendra can be used for both internal ...</td>\n",
       "      <td>A custom data source is a data source that is ...</td>\n",
       "      <td>Yes, AWS Kendra can search across multiple lan...</td>\n",
       "      <td>AWS Kendra handles synonyms and acronyms by us...</td>\n",
       "      <td>Yes, AWS Kendra does support natural language ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct_answer</th>\n",
       "      <td>AWS Kendra is an intelligent search service po...</td>\n",
       "      <td>AWS Kendra supports various data sources, incl...</td>\n",
       "      <td>AWS Kendra uses machine learning models to und...</td>\n",
       "      <td>Some benefits of AWS Kendra include improved s...</td>\n",
       "      <td>AWS Kendra encrypts data at rest and in transi...</td>\n",
       "      <td>Yes, AWS Kendra can be used for both internal ...</td>\n",
       "      <td>Custom data sources in AWS Kendra allow you to...</td>\n",
       "      <td>Yes, AWS Kendra supports multiple languages an...</td>\n",
       "      <td>AWS Kendra automatically recognizes synonyms a...</td>\n",
       "      <td>Yes, AWS Kendra uses natural language processi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.767183</td>\n",
       "      <td>0.741995</td>\n",
       "      <td>0.694686</td>\n",
       "      <td>0.760904</td>\n",
       "      <td>0.738576</td>\n",
       "      <td>0.861344</td>\n",
       "      <td>0.627521</td>\n",
       "      <td>0.787071</td>\n",
       "      <td>0.596884</td>\n",
       "      <td>0.726564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                What is AWS Kendra?  \\\n",
       "generated_answer  AWS Kendra is a cloud-based service that provi...   \n",
       "correct_answer    AWS Kendra is an intelligent search service po...   \n",
       "score                                                      0.767183   \n",
       "\n",
       "                 What types of data sources does AWS Kendra support for indexing?  \\\n",
       "generated_answer  AWS Kendra supports indexing documents in a va...                 \n",
       "correct_answer    AWS Kendra supports various data sources, incl...                 \n",
       "score                                                      0.741995                 \n",
       "\n",
       "                 How does AWS Kendra handle natural language queries?  \\\n",
       "generated_answer  AWS Kendra uses natural language processing an...     \n",
       "correct_answer    AWS Kendra uses machine learning models to und...     \n",
       "score                                                      0.694686     \n",
       "\n",
       "                 What are the benefits of using AWS Kendra for enterprise search?  \\\n",
       "generated_answer  The benefits of using AWS Kendra for enterpris...                 \n",
       "correct_answer    Some benefits of AWS Kendra include improved s...                 \n",
       "score                                                      0.760904                 \n",
       "\n",
       "                 How does AWS Kendra ensure security and compliance?  \\\n",
       "generated_answer  AWS Kendra provides a number of security and c...    \n",
       "correct_answer    AWS Kendra encrypts data at rest and in transi...    \n",
       "score                                                      0.738576    \n",
       "\n",
       "                 Can AWS Kendra be used for both internal and external search scenarios?  \\\n",
       "generated_answer  Yes, AWS Kendra can be used for both internal ...                        \n",
       "correct_answer    Yes, AWS Kendra can be used for both internal ...                        \n",
       "score                                                      0.861344                        \n",
       "\n",
       "                        What are custom data sources in AWS Kendra?  \\\n",
       "generated_answer  A custom data source is a data source that is ...   \n",
       "correct_answer    Custom data sources in AWS Kendra allow you to...   \n",
       "score                                                      0.627521   \n",
       "\n",
       "                   Can AWS Kendra search across multiple languages?  \\\n",
       "generated_answer  Yes, AWS Kendra can search across multiple lan...   \n",
       "correct_answer    Yes, AWS Kendra supports multiple languages an...   \n",
       "score                                                      0.787071   \n",
       "\n",
       "                  How does AWS Kendra handle synonyms and acronyms?  \\\n",
       "generated_answer  AWS Kendra handles synonyms and acronyms by us...   \n",
       "correct_answer    AWS Kendra automatically recognizes synonyms a...   \n",
       "score                                                      0.596884   \n",
       "\n",
       "                 Does AWS Kendra support natural language processing (NLP)?  \n",
       "generated_answer  Yes, AWS Kendra does support natural language ...          \n",
       "correct_answer    Yes, AWS Kendra uses natural language processi...          \n",
       "score                                                      0.726564          "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_initial = pd.DataFrame(score_dict)\n",
    "score_initial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3b940f5c-deae-4e23-972f-b34148bfc54a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7302728295326233"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_initial.iloc[2].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68d3bd9-4563-4452-9176-f1ce3d1601be",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9891fd-a1f2-4a23-a641-d34cca11c574",
   "metadata": {},
   "source": [
    "### Observe the impact of different prompt templates to the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "60014021-9fc6-45b3-a311-b1c07ecb73cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# candidate prompt templates to replace the original template\n",
    "\n",
    "prompt_template_list = \"\"\"\n",
    "    Explore this amiable exchange between a human and a chatty AI, where the AI generously shares numerous specific details from its context. Rest assured that if the AI is uncertain about an answer, it will truthfully express its lack of knowledge.\n",
    "    {context}\n",
    "    Instruction: Utilize the above documents to provide a detailed answer for {question}. Respond with \"don't know\" if the answer is not present in the document.\n",
    "    Solution:\n",
    "\n",
    "    Engage in this delightful conversation between a human and a talkative AI, eager to impart specific contextual information. Should the AI be unable to answer a question, it will honestly say so.\n",
    "    {context}\n",
    "    Instruction: Based on the above documents, respond to {question} with a detailed answer. In case the document doesn't contain the answer, write \"don't know.\"\n",
    "    Solution:\n",
    "\n",
    "    Step into a friendly and informative interaction, where a loquacious AI shares abundant specific context. Should the AI encounter an unanswered question, it will readily admit not knowing the answer.\n",
    "    {context}\n",
    "    Instruction: Based on the above documents, compose a detailed answer for {question}. Indicate \"don't know\" if the document lacks the necessary information.\n",
    "    Solution:\n",
    "\n",
    "    Immerse yourself in this warm and engaging exchange between a human and a voluble AI, which willingly provides specific context details. The AI's honesty shines through as it openly admits its lack of knowledge on certain matters.\n",
    "    {context}\n",
    "    Instruction: Utilize the above documents to craft a detailed answer to {question}. If the answer is not present, kindly respond with \"don't know.\"\n",
    "    Solution:\n",
    "\n",
    "    Discover a cordial dialogue between a human and an articulate AI, proficient in sharing precise context. If the AI cannot provide an answer, it will truthfully say it doesn't know.\n",
    "    {context}\n",
    "    Instruction: Based on the above documents, deliver a comprehensive response to {question}. Answer \"don't know\" if the information is not present in the document.\n",
    "    Solution:\n",
    "\n",
    "    Witness an enjoyable and information-rich interaction, featuring a talkative AI eager to share specific context details. The AI's integrity prevails as it openly acknowledges when it cannot answer a question.\n",
    "    {context}\n",
    "    Instruction: Based on the above documents, provide a detailed answer to {question}. If the answer is missing, respond with \"don't know.\"\n",
    "    Solution:\n",
    "\n",
    "    Prepare yourself for an enlightening conversation, where an AI willingly divulges numerous specific details from its context. Should the AI lack an answer to a question, it will sincerely admit it.\n",
    "    {context}\n",
    "    Instruction: Utilize the above documents to provide a detailed answer for {question}. Indicate \"don't know\" if the answer is not present in the document.\n",
    "    Solution:\n",
    "\n",
    "    Unearth a captivating exchange between a human and an AI, eagerly sharing specific contextual insights. The AI's truthfulness is commendable, as it openly admits not knowing the answer to certain questions.\n",
    "    {context}\n",
    "    Instruction: Based on the above documents, respond to {question} with a detailed answer. If the answer is missing, simply state \"don't know.\"\n",
    "    Solution:\n",
    "\n",
    "    Immerse yourself in a friendly and talkative AI conversation, where specific contextual information abounds. Should the AI encounter an unanswered question, it will forthrightly acknowledge its lack of knowledge.\n",
    "    {context}\n",
    "    Instruction: Using the above documents, provide a detailed answer to {question}. If the document doesn't contain the necessary information, state \"don't know.\"\n",
    "    Solution:\n",
    "\n",
    "    Delve into this amiable and articulate exchange between a human and an AI, proficient in sharing specific context details. The AI's honesty is evident as it admits not knowing the answer to certain questions.\n",
    "    {context}\n",
    "    Instruction: Based on the above documents, furnish a comprehensive response to {question}. Respond with \"don't know\" if the document lacks the necessary information.\n",
    "    Solution:\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ccf38-bdf7-4c19-82cd-940a8c040be6",
   "metadata": {},
   "source": [
    "### run Q & A for each prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a5f26f7e-6c0c-4650-91c7-dd32d4024090",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:47<00:00,  4.76s/it]\n",
      "100%|██████████| 10/10 [00:56<00:00,  5.61s/it]\n",
      "100%|██████████| 10/10 [01:06<00:00,  6.65s/it]\n",
      "100%|██████████| 10/10 [00:58<00:00,  5.81s/it]\n",
      "100%|██████████| 10/10 [00:50<00:00,  5.05s/it]\n",
      "100%|██████████| 10/10 [00:59<00:00,  5.98s/it]\n",
      "100%|██████████| 10/10 [00:50<00:00,  5.04s/it]\n",
      "100%|██████████| 10/10 [01:03<00:00,  6.37s/it]\n",
      "100%|██████████| 10/10 [00:53<00:00,  5.40s/it]\n",
      "100%|██████████| 10/10 [00:43<00:00,  4.40s/it]\n"
     ]
    }
   ],
   "source": [
    "# loop through all the template, each template will be used to answer the 10 questions with Kendra + RAG\n",
    "\n",
    "tmp=[i.strip() for i in prompt_template_list.split('\\n') if i != '']\n",
    "\n",
    "result = list()\n",
    "result_dir = 'result'\n",
    "if not os.path.exists(result_dir): os.mkdir(result_dir)\n",
    "\n",
    "for idx, prompt_template in enumerate([\"\\n\".join(tmp[i: i+4]) for i in range(0, len(tmp), 4)]):\n",
    "    chain = build_chain(prompt_template=prompt_template)\n",
    "    \n",
    "    score_dict = {}\n",
    "    for qq, aa in tqdm(qa_bank.items()):\n",
    "        ans = run_chain(chain, prompt = qq)\n",
    "        score = get_ans_score(aa, ans['answer'].strip(), model=model)\n",
    "        score_dict[qq] = {'generated_answer': ans['answer'].strip(), 'correct_answer': aa, 'score': score.item()}\n",
    "    score_dict['prompt_id'] = idx\n",
    "    score_df = pd.DataFrame(score_dict)\n",
    "    score_df = score_df[['prompt_id'] + list(score_df.columns)[:-1]]\n",
    "    score_df.to_csv(os.path.join(result_dir, str(idx) + '.csv'), index=False)\n",
    "    result.append(score_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9a0c8-7016-4cb3-83cc-311643f822c8",
   "metadata": {},
   "source": [
    "## accumulate score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8fc02c0c-65bf-46de-a2b7-65bc8878d267",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>What is AWS Kendra?</th>\n",
       "      <th>What types of data sources does AWS Kendra support for indexing?</th>\n",
       "      <th>How does AWS Kendra handle natural language queries?</th>\n",
       "      <th>What are the benefits of using AWS Kendra for enterprise search?</th>\n",
       "      <th>How does AWS Kendra ensure security and compliance?</th>\n",
       "      <th>Can AWS Kendra be used for both internal and external search scenarios?</th>\n",
       "      <th>What are custom data sources in AWS Kendra?</th>\n",
       "      <th>Can AWS Kendra search across multiple languages?</th>\n",
       "      <th>How does AWS Kendra handle synonyms and acronyms?</th>\n",
       "      <th>Does AWS Kendra support natural language processing (NLP)?</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0</td>\n",
       "      <td>0.417657</td>\n",
       "      <td>0.198499</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.621194</td>\n",
       "      <td>0.632943</td>\n",
       "      <td>0.841492</td>\n",
       "      <td>0.640973</td>\n",
       "      <td>0.743932</td>\n",
       "      <td>0.601138</td>\n",
       "      <td>0.755836</td>\n",
       "      <td>0.621825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.83542</td>\n",
       "      <td>0.481795</td>\n",
       "      <td>0.789265</td>\n",
       "      <td>0.761355</td>\n",
       "      <td>0.753419</td>\n",
       "      <td>0.857371</td>\n",
       "      <td>0.785025</td>\n",
       "      <td>0.904366</td>\n",
       "      <td>0.625956</td>\n",
       "      <td>0.787716</td>\n",
       "      <td>0.758169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>2</td>\n",
       "      <td>0.752844</td>\n",
       "      <td>0.861995</td>\n",
       "      <td>0.758707</td>\n",
       "      <td>0.762287</td>\n",
       "      <td>0.62823</td>\n",
       "      <td>0.812501</td>\n",
       "      <td>0.794125</td>\n",
       "      <td>0.763514</td>\n",
       "      <td>0.611844</td>\n",
       "      <td>0.763758</td>\n",
       "      <td>0.75098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>3</td>\n",
       "      <td>0.325097</td>\n",
       "      <td>0.449675</td>\n",
       "      <td>0.775506</td>\n",
       "      <td>0.630548</td>\n",
       "      <td>0.511748</td>\n",
       "      <td>0.858838</td>\n",
       "      <td>0.733725</td>\n",
       "      <td>0.758296</td>\n",
       "      <td>0.627244</td>\n",
       "      <td>0.767142</td>\n",
       "      <td>0.643782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>4</td>\n",
       "      <td>0.432453</td>\n",
       "      <td>0.816649</td>\n",
       "      <td>0.782629</td>\n",
       "      <td>0.761355</td>\n",
       "      <td>0.709081</td>\n",
       "      <td>0.884905</td>\n",
       "      <td>0.510897</td>\n",
       "      <td>0.763358</td>\n",
       "      <td>0.628977</td>\n",
       "      <td>0.735579</td>\n",
       "      <td>0.702588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>5</td>\n",
       "      <td>0.737324</td>\n",
       "      <td>0.751643</td>\n",
       "      <td>0.764353</td>\n",
       "      <td>0.761355</td>\n",
       "      <td>0.764598</td>\n",
       "      <td>0.852531</td>\n",
       "      <td>0.738039</td>\n",
       "      <td>0.757733</td>\n",
       "      <td>0.628648</td>\n",
       "      <td>0.761195</td>\n",
       "      <td>0.751742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>6</td>\n",
       "      <td>0.389831</td>\n",
       "      <td>0.705848</td>\n",
       "      <td>0.762999</td>\n",
       "      <td>0.621194</td>\n",
       "      <td>0.52724</td>\n",
       "      <td>0.844929</td>\n",
       "      <td>0.682368</td>\n",
       "      <td>0.757733</td>\n",
       "      <td>0.601138</td>\n",
       "      <td>0.791388</td>\n",
       "      <td>0.668467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>7</td>\n",
       "      <td>0.734867</td>\n",
       "      <td>0.499733</td>\n",
       "      <td>0.772981</td>\n",
       "      <td>0.761355</td>\n",
       "      <td>0.611184</td>\n",
       "      <td>0.862573</td>\n",
       "      <td>0.769958</td>\n",
       "      <td>0.762289</td>\n",
       "      <td>0.628648</td>\n",
       "      <td>0.785208</td>\n",
       "      <td>0.71888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>8</td>\n",
       "      <td>0.463853</td>\n",
       "      <td>0.513102</td>\n",
       "      <td>0.880899</td>\n",
       "      <td>0.761355</td>\n",
       "      <td>0.758081</td>\n",
       "      <td>0.834965</td>\n",
       "      <td>0.770719</td>\n",
       "      <td>0.762016</td>\n",
       "      <td>0.630976</td>\n",
       "      <td>0.766571</td>\n",
       "      <td>0.714254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>9</td>\n",
       "      <td>0.30001</td>\n",
       "      <td>0.472426</td>\n",
       "      <td>0.869748</td>\n",
       "      <td>0.761355</td>\n",
       "      <td>0.399773</td>\n",
       "      <td>0.884905</td>\n",
       "      <td>0.665034</td>\n",
       "      <td>0.763358</td>\n",
       "      <td>0.600109</td>\n",
       "      <td>0.775749</td>\n",
       "      <td>0.649247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prompt_id What is AWS Kendra?  \\\n",
       "score          0            0.417657   \n",
       "score          1             0.83542   \n",
       "score          2            0.752844   \n",
       "score          3            0.325097   \n",
       "score          4            0.432453   \n",
       "score          5            0.737324   \n",
       "score          6            0.389831   \n",
       "score          7            0.734867   \n",
       "score          8            0.463853   \n",
       "score          9             0.30001   \n",
       "\n",
       "      What types of data sources does AWS Kendra support for indexing?  \\\n",
       "score                                           0.198499                 \n",
       "score                                           0.481795                 \n",
       "score                                           0.861995                 \n",
       "score                                           0.449675                 \n",
       "score                                           0.816649                 \n",
       "score                                           0.751643                 \n",
       "score                                           0.705848                 \n",
       "score                                           0.499733                 \n",
       "score                                           0.513102                 \n",
       "score                                           0.472426                 \n",
       "\n",
       "      How does AWS Kendra handle natural language queries?  \\\n",
       "score                                           0.764583     \n",
       "score                                           0.789265     \n",
       "score                                           0.758707     \n",
       "score                                           0.775506     \n",
       "score                                           0.782629     \n",
       "score                                           0.764353     \n",
       "score                                           0.762999     \n",
       "score                                           0.772981     \n",
       "score                                           0.880899     \n",
       "score                                           0.869748     \n",
       "\n",
       "      What are the benefits of using AWS Kendra for enterprise search?  \\\n",
       "score                                           0.621194                 \n",
       "score                                           0.761355                 \n",
       "score                                           0.762287                 \n",
       "score                                           0.630548                 \n",
       "score                                           0.761355                 \n",
       "score                                           0.761355                 \n",
       "score                                           0.621194                 \n",
       "score                                           0.761355                 \n",
       "score                                           0.761355                 \n",
       "score                                           0.761355                 \n",
       "\n",
       "      How does AWS Kendra ensure security and compliance?  \\\n",
       "score                                           0.632943    \n",
       "score                                           0.753419    \n",
       "score                                            0.62823    \n",
       "score                                           0.511748    \n",
       "score                                           0.709081    \n",
       "score                                           0.764598    \n",
       "score                                            0.52724    \n",
       "score                                           0.611184    \n",
       "score                                           0.758081    \n",
       "score                                           0.399773    \n",
       "\n",
       "      Can AWS Kendra be used for both internal and external search scenarios?  \\\n",
       "score                                           0.841492                        \n",
       "score                                           0.857371                        \n",
       "score                                           0.812501                        \n",
       "score                                           0.858838                        \n",
       "score                                           0.884905                        \n",
       "score                                           0.852531                        \n",
       "score                                           0.844929                        \n",
       "score                                           0.862573                        \n",
       "score                                           0.834965                        \n",
       "score                                           0.884905                        \n",
       "\n",
       "      What are custom data sources in AWS Kendra?  \\\n",
       "score                                    0.640973   \n",
       "score                                    0.785025   \n",
       "score                                    0.794125   \n",
       "score                                    0.733725   \n",
       "score                                    0.510897   \n",
       "score                                    0.738039   \n",
       "score                                    0.682368   \n",
       "score                                    0.769958   \n",
       "score                                    0.770719   \n",
       "score                                    0.665034   \n",
       "\n",
       "      Can AWS Kendra search across multiple languages?  \\\n",
       "score                                         0.743932   \n",
       "score                                         0.904366   \n",
       "score                                         0.763514   \n",
       "score                                         0.758296   \n",
       "score                                         0.763358   \n",
       "score                                         0.757733   \n",
       "score                                         0.757733   \n",
       "score                                         0.762289   \n",
       "score                                         0.762016   \n",
       "score                                         0.763358   \n",
       "\n",
       "      How does AWS Kendra handle synonyms and acronyms?  \\\n",
       "score                                          0.601138   \n",
       "score                                          0.625956   \n",
       "score                                          0.611844   \n",
       "score                                          0.627244   \n",
       "score                                          0.628977   \n",
       "score                                          0.628648   \n",
       "score                                          0.601138   \n",
       "score                                          0.628648   \n",
       "score                                          0.630976   \n",
       "score                                          0.600109   \n",
       "\n",
       "      Does AWS Kendra support natural language processing (NLP)? avg_score  \n",
       "score                                           0.755836          0.621825  \n",
       "score                                           0.787716          0.758169  \n",
       "score                                           0.763758           0.75098  \n",
       "score                                           0.767142          0.643782  \n",
       "score                                           0.735579          0.702588  \n",
       "score                                           0.761195          0.751742  \n",
       "score                                           0.791388          0.668467  \n",
       "score                                           0.785208           0.71888  \n",
       "score                                           0.766571          0.714254  \n",
       "score                                           0.775749          0.649247  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate average score for each prompt, indexed by prompt_id\n",
    "\n",
    "result_df = pd.concat(result)\n",
    "\n",
    "result_df_score = result_df.iloc[2::3]\n",
    "result_df_score\n",
    "\n",
    "result_df_score = result_df_score.copy()\n",
    "result_df_score['avg_score'] = result_df_score.iloc[:, 1:].mean(axis=1)\n",
    "\n",
    "result_df_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26261505-bc21-4d12-8681-fc53115dd276",
   "metadata": {},
   "source": [
    "## retrieve best score template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "f3a043d1-467c-4794-9185-edcb75767b42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt_id</th>\n",
       "      <th>What is AWS Kendra?</th>\n",
       "      <th>What types of data sources does AWS Kendra support for indexing?</th>\n",
       "      <th>How does AWS Kendra handle natural language queries?</th>\n",
       "      <th>What are the benefits of using AWS Kendra for enterprise search?</th>\n",
       "      <th>How does AWS Kendra ensure security and compliance?</th>\n",
       "      <th>Can AWS Kendra be used for both internal and external search scenarios?</th>\n",
       "      <th>What are custom data sources in AWS Kendra?</th>\n",
       "      <th>Can AWS Kendra search across multiple languages?</th>\n",
       "      <th>How does AWS Kendra handle synonyms and acronyms?</th>\n",
       "      <th>Does AWS Kendra support natural language processing (NLP)?</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>1</td>\n",
       "      <td>0.83542</td>\n",
       "      <td>0.481795</td>\n",
       "      <td>0.789265</td>\n",
       "      <td>0.761355</td>\n",
       "      <td>0.753419</td>\n",
       "      <td>0.857371</td>\n",
       "      <td>0.785025</td>\n",
       "      <td>0.904366</td>\n",
       "      <td>0.625956</td>\n",
       "      <td>0.787716</td>\n",
       "      <td>0.758169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prompt_id What is AWS Kendra?  \\\n",
       "score          1             0.83542   \n",
       "\n",
       "      What types of data sources does AWS Kendra support for indexing?  \\\n",
       "score                                           0.481795                 \n",
       "\n",
       "      How does AWS Kendra handle natural language queries?  \\\n",
       "score                                           0.789265     \n",
       "\n",
       "      What are the benefits of using AWS Kendra for enterprise search?  \\\n",
       "score                                           0.761355                 \n",
       "\n",
       "      How does AWS Kendra ensure security and compliance?  \\\n",
       "score                                           0.753419    \n",
       "\n",
       "      Can AWS Kendra be used for both internal and external search scenarios?  \\\n",
       "score                                           0.857371                        \n",
       "\n",
       "      What are custom data sources in AWS Kendra?  \\\n",
       "score                                    0.785025   \n",
       "\n",
       "      Can AWS Kendra search across multiple languages?  \\\n",
       "score                                         0.904366   \n",
       "\n",
       "      How does AWS Kendra handle synonyms and acronyms?  \\\n",
       "score                                          0.625956   \n",
       "\n",
       "      Does AWS Kendra support natural language processing (NLP)? avg_score  \n",
       "score                                           0.787716          0.758169  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df_score.loc[result_df_score['avg_score'] == result_df_score['avg_score'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a96426b-bd07-4730-b57d-a79692d9c442",
   "metadata": {},
   "source": [
    "## original template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "92c5de9d-d7d5-43b9-b9a1-b13cf35e1a5f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    The following is a friendly conversation between a human and an AI. \n",
      "    The AI is talkative and provides lots of specific details from its context.\n",
      "    If the AI does not know the answer to a question, it truthfully says it \n",
      "    does not know.\n",
      "    {context}\n",
      "    Instruction: Based on the above documents, provide a detailed answer for, {question} Answer \"don't know\" \n",
      "    if not present in the document. \n",
      "    Solution:\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "    The following is a friendly conversation between a human and an AI. \n",
    "    The AI is talkative and provides lots of specific details from its context.\n",
    "    If the AI does not know the answer to a question, it truthfully says it \n",
    "    does not know.\n",
    "    {context}\n",
    "    Instruction: Based on the above documents, provide a detailed answer for, {question} Answer \"don't know\" \n",
    "    if not present in the document. \n",
    "    Solution:\"\"\"\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c18c7-d788-4e84-ac10-ebcaa02edf49",
   "metadata": {},
   "source": [
    "## improved template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "80a39311-7d87-4100-b2f5-043b1da31fe2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engage in this delightful conversation between a human and a talkative AI, eager to impart specific contextual information. Should the AI be unable to answer a question, it will honestly say so.\n",
      "{context}\n",
      "Instruction: Based on the above documents, respond to {question} with a detailed answer. In case the document doesn't contain the answer, write \"don't know.\"\n",
      "Solution:\n"
     ]
    }
   ],
   "source": [
    "# best template among the 10\n",
    "\n",
    "print([\"\\n\".join(tmp[i: i+4]) for i in range(0, len(tmp), 4)][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff45c99f-6a1f-4590-bb93-cd3954529294",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b373512-849b-4d5a-9669-403d61101447",
   "metadata": {},
   "source": [
    "## improve prompt via LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "cf176f95-c0f9-4a90-ae2a-f551962cc574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:20<00:00,  8.05s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7143150329589844"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region = os.environ[\"AWS_REGION\"]\n",
    "kendra_index_id = os.environ[\"KENDRA_INDEX_ID\"]\n",
    "endpoint_name = os.environ[\"SAGEMAKER_LLM_ENDPOINT\"]\n",
    "\n",
    "content_handler = ContentHandler()\n",
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name=endpoint_name,\n",
    "    region_name=region,\n",
    "    model_kwargs=model_parameters,\n",
    "    content_handler=content_handler\n",
    ")\n",
    "\n",
    "prompt_template_improve = \"\"\"Suggest a more detailed prompt for the following enclosed in three single quotes. \n",
    "                            The prompt should still be an question. The prompt should be different with the original. \n",
    "                            '''{input_text}''' \"\"\"\n",
    "prompt_improve = PromptTemplate.from_template(prompt_template_improve)\n",
    "\n",
    "score_dict_updated = {}\n",
    "chain = build_chain(prompt_template=prompt_template)\n",
    "for qq, aa in tqdm(qa_bank.items()):\n",
    "    qq_refined = llm(prompt_improve.format(input_text=qq)).strip()\n",
    "    ans = run_chain(chain, prompt = qq_refined)\n",
    "    score = get_ans_score(aa, ans['answer'].strip(), model=model)\n",
    "    score_dict_updated[qq] = {'generated_answer': ans['answer'].strip(), 'correct_answer': aa, 'score': score.item()}\n",
    "\n",
    "df = pd.DataFrame(score_dict_updated)\n",
    "\n",
    "## with the same prompt template, modifying the actual prompt is not effective\n",
    "\n",
    "df.iloc[2].mean()"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.g4dn.xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Base Python 2.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-base-python-38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
